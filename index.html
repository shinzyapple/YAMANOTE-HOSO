<!DOCTYPE html>
<html lang="ja">
<head>
  <meta charset="UTF-8">
  <title>文字検出で音声切り替え</title>
</head>
<body>
  <h2>カメラ映像から文字検出</h2>
  <video id="video" width="400" height="300" autoplay playsinline></video>
  <canvas id="canvas" width="400" height="300" style="display:none;"></canvas>
  <p id="result">検出結果: </p>

  <!-- 音声ファイル -->
  <audio id="audio" src="" preload="auto"></audio>

  <script src="https://cdn.jsdelivr.net/npm/tesseract.js@4.0.2/dist/tesseract.min.js"></script>
  <script>
    const video = document.getElementById('video');
    const canvas = document.getElementById('canvas');
    const ctx = canvas.getContext('2d');
    const result = document.getElementById('result');
    const audio = document.getElementById('audio');

    // 検出する文字と対応する音声ファイルを定義
    const audioMap = {
      "Ayase": "audio/1.wav",
      "Kameari": "audio/3.wav",
    };

    let detectedWords = new Set();

    navigator.mediaDevices.getUserMedia({ video: true }).then(stream => {
      video.srcObject = stream;
    }).catch(err => {
      alert("カメラにアクセスできません: " + err);
    });

    setInterval(() => {
      ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
      Tesseract.recognize(canvas, 'jpn', {
        logger: m => console.log(m)
      }).then(({ data: { text } }) => {
        result.innerText = "検出結果: " + text;

        // 検出した文字に対応する音声があれば再生
        for (const word in audioMap) {
          if (text.includes(word) && !detectedWords.has(word)) {
            detectedWords.add(word);
            playAudio(audioMap[word]);
            break;
          }
        }
      });
    }, 4000);

    function playAudio(fileName) {
      audio.src = fileName;
      audio.play().catch(err => {
        console.log("音声再生エラー:", err);
      });
    }
  </script>
</body>
</html>
